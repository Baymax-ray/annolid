{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Annolid_video_batch_inference",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/healthonrails/annolid/blob/main/docs/tutorials/Annolid_video_batch_inference.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "gtCYnCrB8BxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This* notebook provides recipes for batch inference on your videos with a trained model and the datasets used for training the model.\n",
        "You need to upload your the following files from your local drive or mount the Google Drive that contains them. \n",
        "1. Custom COCO Format Dataset (e.g. my_coco_dataset.zip)\n",
        "2. A trained model saved as .pth format (e.g. model_final.pth)\n",
        "3. A folder contains all the videos (e.g. my_videos folder has video files like 1.mp4, 2.avi ...)"
      ],
      "metadata": {
        "id": "7Z2jcRKwUHqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Detectron2"
      ],
      "metadata": {
        "id": "7he396rSMrBX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.3\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "outputs": [],
      "metadata": {
        "id": "vlSWv54MMpNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## It takes a few mintures to install Detectron2 from source. "
      ],
      "metadata": {
        "id": "3EIIwBeZYuhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "dCgNy10xYbf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and install Annolid"
      ],
      "metadata": {
        "id": "Yf7YXWfFZsmf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone --recurse-submodules https://github.com/healthonrails/annolid.git"
      ],
      "outputs": [],
      "metadata": {
        "id": "3HnNyOswKbC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd annolid\n",
        "!pip install -e .\n",
        "%cd /content"
      ],
      "outputs": [],
      "metadata": {
        "id": "WlKFjlxuLRA3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from annolid.annotation.keypoints import save_labels\n",
        "from annolid.postprocessing.quality_control import pred_dict_to_labelme\n",
        "from annolid.data.videos import frame_from_video\n",
        "from annolid.inference.predict import Segmentor"
      ],
      "outputs": [],
      "metadata": {
        "id": "wsW5Q6dwcrta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note: if you encouter errors, please restart the runtime and rerun the above cell."
      ],
      "metadata": {
        "id": "YNj0PlB0diC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local file system (Please skip this section if you want to use the files in your Google Drive)"
      ],
      "metadata": {
        "id": "eikfzi8ZT_rW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading files from your local file system\n",
        "\n",
        "`files.upload` returns a dictionary of the files which were uploaded.\n",
        "The dictionary is keyed by the file name and values are the data which were uploaded."
      ],
      "metadata": {
        "id": "BaCkyg5CV5jF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "#list(uploaded.keys())[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "vz-jH8T_Uk2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Or mount your Google Drive on this runtime and accesss files from there"
      ],
      "metadata": {
        "id": "64TzYFFufN8t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "id": "dhVnij13fm1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example for unzip your COCO format dataset zip file"
      ],
      "metadata": {
        "id": "VrhkLihIiKpt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#!unzip /content/digging_videos_coco_dataset.zip -d /content\n",
        "try:\n",
        "   dataset = list(uploaded.keys())[0]\n",
        "except:\n",
        "     #please update the dataset zip file\n",
        "     # path if do not upload with the previs cell\n",
        "     dataset = \"/content/digging_videos_coco_dataset.zip\" #@param\n",
        "\n",
        "DATASET_DIR = dataset.replace('.zip','')\n",
        "!unzip $dataset -d $DATASET_DIR"
      ],
      "outputs": [],
      "metadata": {
        "id": "ymtCoovZM85D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Change the DATASET_DIR to the exact location, if you did not use the upload cell.\n",
        "DATASET_DIR = \"/content/digging_videos_coco_dataset\" #@param\n",
        "# The path to the model pth file\n",
        "MODEL_PATH =  \"/content/model_final.pth\" #@param\n",
        "#folder contains all your videos\n",
        "VIDEOS_FOLDER = '/content/videos'  #@param"
      ],
      "outputs": [],
      "metadata": {
        "id": "UqPPW1kMM-AH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the predictor"
      ],
      "metadata": {
        "id": "hPPf4-n7aLMF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Please update this variable to the top n number of instances of the same class in a given frame\n",
        "# e.g. 4  will save top 4 predictions based on the class score. \n",
        "NUM_INSTANCES_PER_CLASS = 4 #@param\n",
        "predictor = Segmentor(DATASET_DIR,MODEL_PATH,num_instances_per_class=NUM_INSTANCES_PER_CLASS) "
      ],
      "outputs": [],
      "metadata": {
        "id": "RWJ0BeYdOpdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find all the video files in the given `VIDEOS_FOLDER`"
      ],
      "metadata": {
        "id": "O5b7pb7oljyO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "video_files = glob.glob(VIDEOS_FOLDER + '/*.*')"
      ],
      "outputs": [],
      "metadata": {
        "id": "frXbD7n6ZG5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch inference for the videos"
      ],
      "metadata": {
        "id": "zxe7zEbZl1nS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# select number of frames to skip e.g. 2 for every other frames \n",
        "# if skip_frames = 30, every 30th frame will be processed.\n",
        "# default 1 no skipping\n",
        "skip_frames = 10 #@param {type: \"slider\", min:0, max:30, step: 1}\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if cap.isOpened():\n",
        "    cap.release()\n",
        "    print(\"Working on video, \", video_file)\n",
        "    predictor.on_video(video_file,\n",
        "                       skip_frames=skip_frames,\n",
        "                       on_keyframes=False\n",
        "                       )\n",
        "  else:\n",
        "    print(\"Cannot open this file\", video_file)\n",
        "    cap.release()"
      ],
      "outputs": [],
      "metadata": {
        "id": "UGe0hazbahlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading files to your local file system\n",
        "\n",
        "`files.download` will invoke a browser download of the file to your local computer.\n"
      ],
      "metadata": {
        "id": "hauvGV4hV-Mh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import files\n",
        "tracking_csv_files = glob.glob(str(Path(DATASET_DIR).parent) + '/*mask*tracking*.csv')\n",
        "for tcf in tracking_csv_files:\n",
        "    files.download(tcf)"
      ],
      "outputs": [],
      "metadata": {
        "id": "p2E4EKhCWEC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Or saving the tracking results csv files to your Google Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "u22w3BFiOveA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import shutil"
      ],
      "outputs": [],
      "metadata": {
        "id": "RWSJpsyKqHjH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for tcf in tracking_csv_files:\n",
        "    shutil.copy(tcf, '/content/drive/MyDrive/')"
      ],
      "outputs": [],
      "metadata": {
        "id": "tYXQViLfAvwk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "outputs": [],
      "metadata": {
        "id": "D78AM1fFt2ty"
      }
    }
  ]
}